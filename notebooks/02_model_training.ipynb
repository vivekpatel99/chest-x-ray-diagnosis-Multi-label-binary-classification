{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-02T07:06:22.039762Z",
     "iopub.status.busy": "2025-03-02T07:06:22.039402Z",
     "iopub.status.idle": "2025-03-02T07:06:32.200919Z",
     "shell.execute_reply": "2025-03-02T07:06:32.199836Z",
     "shell.execute_reply.started": "2025-03-02T07:06:22.039734Z"
    }
   },
   "source": [
    "# NIH Chest X-ray Multi label Binary classification using Tensorflow Densenet121 (Transfer learning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/chest-x-ray-diagnosis'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go to project root folder\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T10:25:58.836148Z",
     "iopub.status.busy": "2025-03-02T10:25:58.835783Z",
     "iopub.status.idle": "2025-03-02T10:26:14.649285Z",
     "shell.execute_reply": "2025-03-02T10:26:14.647955Z",
     "shell.execute_reply.started": "2025-03-02T10:25:58.836120Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 11:19:05.357058: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742469545.370087  113993 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742469545.374203  113993 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T10:26:14.652600Z",
     "iopub.status.busy": "2025-03-02T10:26:14.651810Z",
     "iopub.status.idle": "2025-03-02T10:26:14.662952Z",
     "shell.execute_reply": "2025-03-02T10:26:14.661875Z",
     "shell.execute_reply.started": "2025-03-02T10:26:14.652529Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')], '2.18.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_gpu = tf.config.list_physical_devices('GPU')\n",
    "if not found_gpu:\n",
    "     raise Exception(\"No GPU found\")\n",
    "found_gpu, tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T10:26:14.665526Z",
     "iopub.status.busy": "2025-03-02T10:26:14.665122Z",
     "iopub.status.idle": "2025-03-02T10:26:15.927292Z",
     "shell.execute_reply": "2025-03-02T10:26:15.926295Z",
     "shell.execute_reply.started": "2025-03-02T10:26:14.665487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import opendatasets as od\n",
    "\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# auto reload libs\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = 'https://www.kaggle.com/datasets/nih-chest-xrays/sample'\n",
    "\n",
    "# Look into the data directory\n",
    "datasets = 'datasets/sample'\n",
    "dataset_path = Path(datasets)\n",
    "IMAGE_DIR = dataset_path /'sample/images'\n",
    "CSV_PATH = dataset_path /'sample/sample_labels.csv'\n",
    "dataset_path.mkdir(parents=True, exist_ok=True)\n",
    "if not dataset_path.is_dir():\n",
    "    od.download(dataset_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/sample/sample/images\n"
     ]
    }
   ],
   "source": [
    "from hydra import initialize, compose\n",
    "\n",
    "# https://gist.github.com/bdsaglam/586704a98336a0cf0a65a6e7c247d248\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "    print(cfg.DATASET_DIRS.TRAIN_IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = cfg.TRAIN.IMG_SIZE\n",
    "BATCH_SIZE = cfg.TRAIN.BATCH_SIZE\n",
    "NUM_EPOCHS = cfg.TRAIN.NUM_EPOCHS\n",
    "LEARNING_RATE = cfg.TRAIN.LEARNING_RATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_colums = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion',\n",
    "#        'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'No Finding',\n",
    "#        'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
    "# 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion',\n",
    "\n",
    "# labels =['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion',\n",
    "#        'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass',\n",
    "#        'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
    "CLASSES_NAME = ['Atelectasis','Effusion','Infiltration', 'Mass', 'No Finding']#,'Nodule']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-20 11:21:38,761 — src.data_loader.chest_x_ray_preprocessor — INFO — Getting training and validation datasets with batch size:None\n",
      "2025-03-20 11:21:38,764 — src.data_loader.chest_x_ray_preprocessor — INFO — Loading and preprocessing dataframe\n",
      "2025-03-20 11:21:38,772 — src.data_loader.chest_x_ray_preprocessor — INFO — Cleaning up training dataframe\n",
      "2025-03-20 11:21:38,800 — src.data_loader.chest_x_ray_preprocessor — INFO — Loaded dataframe with shape: (5606, 2) and 5606 rows\n",
      "2025-03-20 11:21:38,823 — src.data_loader.chest_x_ray_preprocessor — INFO — training split: 3947 and validation split: 987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-20 11:21:39,481 — src.data_loader.chest_x_ray_preprocessor — INFO — Normalization layer adapted\n",
      "WARNING: AutoGraph could not transform <bound method PercentStyle._format of <logging.PercentStyle object at 0x7db436461610>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'NoneType' object has no attribute '_fields'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2025-03-20 11:21:39,921 — src.data_loader.chest_x_ray_preprocessor — INFO — Normalizing image\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7db5b45d1160>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2025-03-20 11:21:40,813 — src.data_loader.chest_x_ray_preprocessor — INFO — Preparing training dataset with augmentation\n",
      "2025-03-20 11:21:41,413 — src.data_loader.chest_x_ray_preprocessor — INFO — Augmenting image\n",
      "2025-03-20 11:21:41,874 — src.data_loader.chest_x_ray_preprocessor — INFO — Augmenting image\n"
     ]
    }
   ],
   "source": [
    "from src.data_loader.chest_x_ray_preprocessor import ChestXRayPreprocessor\n",
    "\n",
    "preprocessor = ChestXRayPreprocessor(cfg, labels=CLASSES_NAME)\n",
    "train_ds, valid_ds, pos_weights, neg_weights, steps_per_epoch = preprocessor.get_training_and_validation_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 350, 350, 3) (16, 5)\n",
      "(350, 350, 3) -2.1179042 2.0638473 tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]], shape=(10, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_ds.take(1):\n",
    "    images, labels = batch\n",
    "    print(images.shape, labels.shape)\n",
    "    print(images[0].shape, images[0].numpy().min(), images[0].numpy().max(), labels[0])\n",
    "    print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 350, 350, 3) (16, 5)\n",
      "(350, 350, 3) -2.117904 2.64 tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]], shape=(10, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for batch in valid_ds.take(1):\n",
    "    images, labels = batch\n",
    "    print(images.shape, labels.shape)\n",
    "    print(images[0].shape, images[0].numpy().min(), images[0].numpy().max(), labels[0])\n",
    "    print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_images(train_ds, num_images=9):\n",
    "  \"\"\"\n",
    "  Plots a random sample of images and their corresponding labels from a TensorFlow dataset.\n",
    "\n",
    "  Args:\n",
    "    train_ds: A TensorFlow dataset object containing image-label pairs.\n",
    "    num_images: The number of images to plot (default: 9).\n",
    "  \"\"\"\n",
    "\n",
    "  # Ensure the dataset is shuffled (if it's not already)\n",
    "  train_ds = train_ds.shuffle(buffer_size=1024)\n",
    "\n",
    "  # Take a batch of images and labels\n",
    "  _images = []\n",
    "  _labels = []\n",
    "  for images, labels in train_ds:\n",
    "      for image, label in zip(images, labels):\n",
    "        _images.append(image)\n",
    "        _labels.append(label)\n",
    "        if len(images) >= num_images:\n",
    "            break\n",
    "        \n",
    "      break\n",
    "\n",
    "  # Create a figure and axes for the plot\n",
    "  plt.figure(figsize=(10, 10))\n",
    "\n",
    "  # Iterate through the images and plot them\n",
    "  for i in range(num_images):\n",
    "    ax = plt.subplot(int(num_images**0.5), int(num_images**0.5), i + 1) # Create a grid of subplots\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"), cmap='gray') # Convert to numpy and uint8 for display\n",
    "    plt.title(f\"Label: {labels[i].numpy()}\") # Display the label\n",
    "    plt.axis(\"off\") # Hide the axes\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_images(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Class Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = train_cat_labels_df.shape[0]\n",
    "# positive_frequencies = (train_cat_labels_df==1).sum()/N\n",
    "# negative_frequencies = (train_cat_labels_df==0).sum()/N\n",
    "# positive_frequencies, negative_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = pd.DataFrame(list(positive_frequencies.items()), columns=['class', 'positives'])\n",
    "# data_df['negatives'] = negative_frequencies.values\n",
    "# data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df.plot.bar(x='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see in the above plot, the contributions of positive cases is significantly lower than that of the negative ones. However, we want the contributions to be equal. One way of doing this is by multiplying each example from each class by a class-specific weight factor, $w_{pos}$ and $w_{neg}$, so that the overall contribution of each class is the same. \n",
    "\n",
    "To have this, we want \n",
    "\n",
    "$$w_{pos} \\times freq_{p} = w_{neg} \\times freq_{n},$$\n",
    "\n",
    "which we can do simply by taking \n",
    "\n",
    "$$w_{pos} = freq_{neg}$$\n",
    "$$w_{neg} = freq_{pos}$$\n",
    "\n",
    "This way, we will be balancing the contribution of positive and negative labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _pos_weights = negative_frequencies.values\n",
    "# _neg_weights = positive_frequencies.values\n",
    "# positive_frequencies.values\n",
    "\n",
    "# Try adjusting the weight balance slightly\n",
    "# pos_weights = np.sqrt(negative_frequencies.values) * 0.8  # Reduce positive weight slightly\n",
    "# neg_weights = np.sqrt(positive_frequencies.values) * 1.2  # Increase negative weight slightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_contirbution = positive_frequencies * _pos_weights\n",
    "# neg_contribution = negative_frequencies * _neg_weights\n",
    "\n",
    "# pos_contirbution, neg_contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted_data_df = pd.DataFrame(list(pos_contirbution.items()), columns=['class', 'positives'])\n",
    "# weighted_data_df['negatives'] = neg_contribution.values\n",
    "# weighted_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted_data_df.plot.bar(x='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted loss calculation to handle class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the above figure shows, by applying these weightings the positive and negative labels within each class would have the same aggregate contribution to the loss function. Now let's implement such a loss function. \n",
    "\n",
    "After computing the weights, our final weighted loss for each training case will be \n",
    "\n",
    "$$\\mathcal{L}_{cross-entropy}^{w}(x) = - (w_{p} y \\log(f(x)) + w_{n}(1-y) \\log( 1 - f(x) ) ).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "@keras.saving.register_keras_serializable()\n",
    "def _get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n",
    "    \"\"\"\n",
    "    Return weighted loss function given negative weights and positive weights.\n",
    "\n",
    "    Args:\n",
    "      pos_weights (np.array): array of positive weights for each class, size (num_classes)\n",
    "      neg_weights (np.array): array of negative weights for each class, size (num_classes)\n",
    "    \n",
    "    Returns:\n",
    "      weighted_loss (function): weighted loss function\n",
    "    \"\"\"\n",
    "    @keras.saving.register_keras_serializable()\n",
    "    def weighted_loss(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Return weighted loss value. \n",
    "\n",
    "        Args:\n",
    "            y_true (Tensor): Tensor of true labels, size is (num_examples, num_classes)\n",
    "            y_pred (Tensor): Tensor of predicted labels, size is (num_examples, num_classes)\n",
    "        Returns:\n",
    "            loss (float): overall scalar loss summed across all classes\n",
    "        \"\"\"\n",
    "        # initialize loss to zero\n",
    "        loss = 0.0\n",
    "\n",
    "        for i in range(len(pos_weights)):\n",
    "            y = y_true[:, i]\n",
    "            f_of_x = y_pred[:, i]\n",
    "\n",
    "            f_of_x_log = K.log(f_of_x + epsilon)\n",
    "            f_of_x_1_min_log = K.log((1-f_of_x) + epsilon)\n",
    "\n",
    "            first_term = pos_weights[i] * y * f_of_x_log\n",
    "            sec_term = neg_weights[i] * (1-y) * f_of_x_1_min_log\n",
    "            loss_per_col = - K.mean(first_term + sec_term)\n",
    "            loss += loss_per_col\n",
    "        return loss\n",
    "\n",
    "    return weighted_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare DenseNet121 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "to_monitor = 'val_AUC'\n",
    "mode = 'max'\n",
    "mlflow.start_run()\n",
    "mlflow.tensorflow.autolog(log_models=True, \n",
    "                        log_datasets=False, \n",
    "                        log_input_examples=True,\n",
    "                        log_model_signatures=True,\n",
    "                        keras_model_kwargs={\"save_format\": \"keras\"},\n",
    "                        checkpoint_monitor=to_monitor, \n",
    "                        checkpoint_mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DenseNet121(\n",
    "     include_top=False,\n",
    "     weights=None, #'imagenet', \n",
    "     input_shape=(IMAGE_SIZE, IMAGE_SIZE, 1)  \n",
    ")\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# and a logistic layer\n",
    "predictions = Dense(len(CLASSES_NAME), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    'binary_accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='AUC'), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.weighted_loss.weighted_loss import get_weighted_loss  \n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.AdamW(), \n",
    "               loss=get_weighted_loss(pos_weights, neg_weights),\n",
    "        metrics=METRICS)     \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_POINT_DIR = 'exported_models'\n",
    "checkpoint_prefix = os.path.join(CHECK_POINT_DIR, \"ckpt_{epoch}.keras\")\n",
    "LOG_DIR = 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                        save_best_only=True, # Save only the best model based 'to_monitor'\n",
    "                                        monitor=to_monitor,\n",
    "                                        mode=mode,\n",
    "                                        verbose=1),  # Display checkpoint saving messages\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=to_monitor,\n",
    "                                        mode=mode, factor=0.1, patience=5, min_lr=1e-7),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=to_monitor,\n",
    "                                        mode=mode, patience=10, restore_best_weights=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, \n",
    "                    validation_data=valid_ds,\n",
    "                    batch_size=cfg.TRAIN.BATCH_SIZE,\n",
    "                    epochs = cfg.TRAIN.NUM_EPOCHS,\n",
    "                    callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, TensorSpec\n",
    "import numpy as np\n",
    "\n",
    "# 1. Input Schema\n",
    "# -----------------\n",
    "# Your input is a batch of images with shape (32, 240, 240, 3)\n",
    "# We use -1 to indicate that the batch size can vary.\n",
    "input_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, IMAGE_SIZE, IMAGE_SIZE, 1), \"image\")])\n",
    "\n",
    "# 2. Output Schema - Multilabel binary classification head\n",
    "# ------------------\n",
    "# Your model outputs a list of two arrays. We need to define a schema for each.\n",
    "# Array 1: Shape (1, 4)\n",
    "output_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, len(CLASSES_NAME)), \"classification\")])\n",
    "\n",
    "# 3. Model Signature\n",
    "# --------------------\n",
    "# Combine the input and output schemas into a ModelSignature\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "mlflow.tensorflow.log_model(\n",
    "    model,\n",
    "    \"best_model\",\n",
    "    signature=signature,\n",
    "    code_paths=[\"src\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['AUC'])\n",
    "plt.plot(history.history['val_AUC'])\n",
    "plt.legend(['AUC', 'val_AUC'])\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\"Training AUC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader.chest_x_ray_preprocessor import ChestXRayPreprocessor\n",
    "\n",
    "test_prorcessor  = ChestXRayPreprocessor(cfg, labels=CLASSES_NAME)\n",
    "test_ds = test_prorcessor.get_test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_ds.take(1):\n",
    "    images, labels = batch\n",
    "    print(images.shape, labels.shape)\n",
    "    print(images[0].shape, images[0].numpy().min(), images[0].numpy().max(), labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(test_ds, return_dict=True, batch_size=BATCH_SIZE)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_metrics(result)\n",
    "mlflow.end_run()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_ds)\n",
    "preds = preds.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = tf.keras.saving.load_model('exported_models/ckpt_2.keras')\n",
    "tf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = 'runs:/74cb397adcc642459ac5b1cd754cf74c/best_model'\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_uri=model_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4667,
     "sourceId": 7773,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
